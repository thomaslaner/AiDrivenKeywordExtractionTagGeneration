{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e81998",
   "metadata": {},
   "source": [
    "# Set input- & output-files and API-Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09eb267",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFilePath=\"\"\n",
    "outputFilePath=\"\"\n",
    "APIKey=\"\"\n",
    "taggingPrompt=\"\"\"\n",
    "Describe these images with a set of tags so that they can then be used when creating content. Identify:\n",
    "- Main subjects, objects, people:\n",
    "    - individuals (names if possible)\n",
    "    - cars, planes, skis etc. with model, livery, specs\n",
    "    - Technical components (e.g.: front suspension) - be precise (propellor airplane, jet plane)\n",
    "- Depicted Actions, activities\n",
    "- Setting, environment\n",
    "- brands, logos, flags\n",
    "\n",
    "Return only a JSON array of tags with no additional text:\n",
    "[\"tag1\", \"tag2\", \"tag3\"]\n",
    "\"\"\"\n",
    "gptModel=\"gpt-4.1-mini\"\n",
    "modelTemperature=0.3 # Temperature for randomness in the model's output\n",
    "detailLevel=\"low\" # Options: low, high\n",
    "apiDelaySeconds=1.0 # Delay between API calls in seconds to prevent rate limiting\n",
    "\n",
    "# Configuration parameters for multiple runs\n",
    "rerunCount=0 # Number of additional runs for each image\n",
    "consolidationPrompt=\"\"\"\n",
    "Review this image and analyze the provided tags from previous model runs.\n",
    "Create a final, consolidated list of accurate tags by:\n",
    "1. Keeping only tags that actually appear in the image\n",
    "2. Removing duplicates or near-duplicates\n",
    "3. Ensuring consistent naming (e.g., choose either 'Formula 1' or 'F1', not both)\n",
    "4. Adding any important missing tags\n",
    "\n",
    "Return only a JSON array of finalized tags with no additional text:\n",
    "[\"tag1\", \"tag2\", \"tag3\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d421dc",
   "metadata": {},
   "source": [
    "# Helper classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d81523",
   "metadata": {},
   "source": [
    "### Image Processor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0ec153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import logging\n",
    "import base64\n",
    "import glob\n",
    "from typing import List, Dict, Optional, Any, Set\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n",
    "class ImageProcessor:\n",
    "    \"\"\"Handle image processing and file operations\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_image_file(file_path: str) -> bool:\n",
    "        \"\"\"Check if the file is an image based on its extension\"\"\"\n",
    "        image_extensions = [\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".webp\"]\n",
    "        _, ext = os.path.splitext(file_path.lower())\n",
    "        return ext in image_extensions\n",
    "    \n",
    "    @staticmethod\n",
    "    def encode_image(image_path: str) -> Optional[str]:\n",
    "        \"\"\"Encode image to base64 with proper error handling\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error encoding image '{image_path}': {e}\")\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_image_files(directory_path: str) -> List[str]:\n",
    "        \"\"\"Get all image files from the specified directory\"\"\"\n",
    "        if not os.path.exists(directory_path):\n",
    "            print(f\"Directory '{directory_path}' does not exist\")\n",
    "            return []\n",
    "            \n",
    "        # Find all image files in the directory\n",
    "        image_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.gif\", \"*.bmp\", \"*.webp\"]\n",
    "        image_files = []\n",
    "        \n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(glob.glob(os.path.join(directory_path, ext)))\n",
    "            image_files.extend(glob.glob(os.path.join(directory_path, ext.upper())))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"No image files found in '{directory_path}'\")\n",
    "            return []\n",
    "            \n",
    "        print(f\"Found {len(image_files)} image files in '{directory_path}'\")\n",
    "        return image_files\n",
    "    \n",
    "    @staticmethod\n",
    "    def deduplicate_tags(tag_lists: List[List[str]]) -> List[str]:\n",
    "        \"\"\"Flatten and deduplicate tags from multiple lists while preserving order\"\"\"\n",
    "        unique_tags = []\n",
    "        seen = set()\n",
    "        \n",
    "        for tags in tag_lists:\n",
    "            for tag in tags:\n",
    "                # Convert to lowercase for comparison but keep original case for output\n",
    "                if tag.lower() not in seen:\n",
    "                    unique_tags.append(tag)\n",
    "                    seen.add(tag.lower())\n",
    "                    \n",
    "        return unique_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ecf18",
   "metadata": {},
   "source": [
    "### GPT Vision Client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1959e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Optional, Dict, List, Any\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "\n",
    "class GptVisionClient:\n",
    "    \"\"\"Handle GPT Vision API interactions and response processing\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, model: str, temperature: float = 0.3, detail_level: str = \"low\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.detail_level = detail_level\n",
    "    \n",
    "    def call_api(self, image_path: str, prompt: str, print_output: bool = False, retries: int = 3, backoff: float = 2.0) -> Optional[str]:\n",
    "        \"\"\"Call GPT Vision API with error handling and exponential backoff retries\"\"\"\n",
    "        base64_image = ImageProcessor.encode_image(image_path)\n",
    "        if not base64_image:\n",
    "            logging.error(f\"Failed to encode image: {image_path}\")\n",
    "            return None\n",
    "        \n",
    "        attempt = 0\n",
    "        while attempt < retries:\n",
    "            try:\n",
    "                client = OpenAI(api_key=self.api_key)\n",
    "                response = client.responses.create(\n",
    "                    model=self.model,\n",
    "                    input=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                { \"type\": \"input_text\", \"text\": prompt },\n",
    "                                {\n",
    "                                    \"type\": \"input_image\",\n",
    "                                    \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                                    \"detail\": self.detail_level\n",
    "                                },\n",
    "                            ],\n",
    "                        }\n",
    "                    ],\n",
    "                    temperature=self.temperature,\n",
    "                    \n",
    "                )\n",
    "                if print_output:\n",
    "                    print(response.output_text)\n",
    "                return response.output_text\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                wait_time = backoff ** attempt\n",
    "                print(f\"API call error ({attempt}/{retries}): {e}. Retrying in {wait_time} seconds...\")\n",
    "                if attempt < retries:\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(\"Maximum retries reached, skipping this image.\")\n",
    "                    return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_output(gpt_output_str: Optional[str]) -> Optional[List[str]]:\n",
    "        \"\"\"Process GPT output with validation\"\"\"\n",
    "        if not gpt_output_str:\n",
    "            return None\n",
    "\n",
    "        # Extract JSON part from potential code blocks or extra text\n",
    "        json_match = re.search(r'\\[\\s*\".*\"\\s*(,\\s*\".*\")*\\s*\\]', gpt_output_str)\n",
    "        if json_match:\n",
    "            gpt_output_str = json_match.group(0)\n",
    "            \n",
    "        try:\n",
    "            tags = json.loads(gpt_output_str)\n",
    "            if isinstance(tags, list):\n",
    "                return tags\n",
    "            else:\n",
    "                print(f\"Error: Expected a list of tags but got {type(tags)}\")\n",
    "                return None\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing JSON: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_tags(self, image_path: str, prompt: str, print_output: bool = False) -> Optional[List[str]]:\n",
    "        \"\"\"Generate tags for an image using the given prompt\"\"\"\n",
    "        output = self.call_api(image_path, prompt, print_output)\n",
    "        return self.process_output(output)\n",
    "    \n",
    "    def consolidate_tags(self, image_path: str, all_tags: List[str], prompt: str) -> Optional[List[str]]:\n",
    "        \"\"\"Consolidate tags by validating them against the image\"\"\"\n",
    "        # Create a consolidated prompt that includes the tags to verify\n",
    "        full_prompt = prompt + \"\\n\\nPreviously identified tags: [\" + \", \".join(f'\"{tag}\"' for tag in all_tags) + \"]\"\n",
    "        return self.generate_tags(image_path, full_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207b14d",
   "metadata": {},
   "source": [
    "### Data output helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d29400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Set, Optional, Tuple\n",
    "\n",
    "class CsvHandler:\n",
    "    \"\"\"Handle CSV operations with context management\"\"\"\n",
    "    def __init__(self, filename: str, fieldnames: List[str]):\n",
    "        self.filename = filename\n",
    "        self.fieldnames = fieldnames\n",
    "        self._existing_entries: Optional[Set[str]] = None\n",
    "\n",
    "    @property\n",
    "    def existing_entries(self) -> Set[str]:\n",
    "        \"\"\"Lazily load existing entries as filename strings\"\"\"\n",
    "        if self._existing_entries is None:\n",
    "            self._existing_entries = self._load_existing_entries()\n",
    "        return self._existing_entries\n",
    "\n",
    "    def _load_existing_entries(self) -> Set[str]:\n",
    "        if not os.path.exists(self.filename):\n",
    "            return set()\n",
    "        with open(self.filename, mode='r', encoding='utf-8') as f:\n",
    "            return {row['fileName'] for row in csv.DictReader(f)}\n",
    "\n",
    "    def write_tags(self, tag_results: List[Dict]) -> None:\n",
    "        \"\"\"Write new tag results to CSV file\"\"\"\n",
    "        new_entries = [\n",
    "            entry for entry in tag_results\n",
    "            if entry.get('fileName') not in self.existing_entries\n",
    "        ]\n",
    "\n",
    "        if not new_entries:\n",
    "            print(\"No new entries to write\")\n",
    "            return\n",
    "\n",
    "        mode = 'a' if os.path.exists(self.filename) else 'w'\n",
    "        with open(self.filename, mode=mode, newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=self.fieldnames)\n",
    "            if mode == 'w':\n",
    "                writer.writeheader()\n",
    "            writer.writerows(new_entries)\n",
    "\n",
    "        print(f\"Wrote {len(new_entries)} new entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48e2bc",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07dce92",
   "metadata": {},
   "source": [
    "### Get all image files from input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90df223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 image files in 'images_sample'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['images_sample/SI202503310625.jpg',\n",
       " 'images_sample/SI202407060351.jpg',\n",
       " 'images_sample/SI202503041658.jpg',\n",
       " 'images_sample/SI202504020575.jpg',\n",
       " 'images_sample/SI202504021111.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize processor and client\n",
    "image_processor = ImageProcessor()\n",
    "gpt_client = GptVisionClient(\n",
    "    api_key=APIKey,\n",
    "    model=gptModel,\n",
    "    temperature=modelTemperature,\n",
    "    detail_level=detailLevel\n",
    ")\n",
    "\n",
    "# Get all image files from input directory\n",
    "image_files = image_processor.get_image_files(inputFilePath)\n",
    "image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42021cc",
   "metadata": {},
   "source": [
    "### Process images with GPT Vision (Multiple Runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9457af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images_sample/SI202503310625.jpg\n",
      "Run 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 14:44:26,413 [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Formula 1 car\", \"Red Bull Racing\", \"car nose\", \"front wing\", \"suspension arms\", \"sponsor logos\", \"Hard Rock\", \"TAG Heuer\", \"Visa\", \"Gate.io\", \"AT&T\", \"Ava Trade\", \"Maui Jim\", \"CDW\", \"neat\", \"Pirelli\", \"Mobil 1\", \"Oracle\", \"number 1\", \"racing livery\", \"motorsport\", \"racing car detail\"]\n",
      "Run 1: Found 22 tags\n",
      "After deduplication: 22 unique tags\n",
      "Final tags for SI202503310625.jpg: Formula 1 car, Red Bull Racing, car nose, front wing, suspension arms, sponsor logos, Hard Rock, TAG Heuer, Visa, Gate.io, AT&T, Ava Trade, Maui Jim, CDW, neat, Pirelli, Mobil 1, Oracle, number 1, racing livery, motorsport, racing car detail\n",
      "--------------------------------------------------\n",
      "Processing images_sample/SI202407060351.jpg\n",
      "Run 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 14:44:37,954 [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"vintage warplanes\", \"aerial formation flying\", \"smoke trails\", \"mountain landscape\", \"green fields\", \"rural area\", \"aerial photography\", \"propeller aircraft\", \"airshow\", \"WWII fighter planes\", \"blue sky\", \"scenic valley\", \"highway\", \"industrial area\"]\n",
      "Run 1: Found 14 tags\n",
      "After deduplication: 14 unique tags\n",
      "Final tags for SI202407060351.jpg: vintage warplanes, aerial formation flying, smoke trails, mountain landscape, green fields, rural area, aerial photography, propeller aircraft, airshow, WWII fighter planes, blue sky, scenic valley, highway, industrial area\n",
      "--------------------------------------------------\n",
      "Processing images_sample/SI202503041658.jpg\n",
      "Run 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 14:44:47,920 [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"skiers\", \"Henrik Kristoffersen\", \"Lucas Pinheiro Braathen\", \"Alexis Pinturault\", \"ski poles\", \"ski boots\", \"ski race bibs\", \"ski competition\", \"ski World Cup\", \"snow\", \"celebration\", \"winter sports\", \"ski race podium\", \"Red Bull logo\", \"Audi logo\", \"Longines logo\", \"Vedestein logo\", \"I Feel Slovenia banner\", \"Kranjska Gora\", \"ski suits\", \"ski helmets\", \"ski goggles\"]\n",
      "Run 1: Found 22 tags\n",
      "After deduplication: 22 unique tags\n",
      "Final tags for SI202503041658.jpg: skiers, Henrik Kristoffersen, Lucas Pinheiro Braathen, Alexis Pinturault, ski poles, ski boots, ski race bibs, ski competition, ski World Cup, snow, celebration, winter sports, ski race podium, Red Bull logo, Audi logo, Longines logo, Vedestein logo, I Feel Slovenia banner, Kranjska Gora, ski suits, ski helmets, ski goggles\n",
      "--------------------------------------------------\n",
      "Processing images_sample/SI202504020575.jpg\n",
      "Run 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 14:44:56,752 [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Formula 1 drivers\", \"racing suits\", \"Red Bull Racing\", \"AlphaTauri\", \"Oracle Red Bull Racing cap\", \"smiling\", \"sitting\", \"race track environment\", \"sponsor logos\", \"Visa\", \"AT&T\", \"Honda\", \"Rauch\", \"ROKiT\", \"HRC\", \"Red Bull logos\", \"team members\"]\n",
      "Run 1: Found 17 tags\n",
      "After deduplication: 17 unique tags\n",
      "Final tags for SI202504020575.jpg: Formula 1 drivers, racing suits, Red Bull Racing, AlphaTauri, Oracle Red Bull Racing cap, smiling, sitting, race track environment, sponsor logos, Visa, AT&T, Honda, Rauch, ROKiT, HRC, Red Bull logos, team members\n",
      "--------------------------------------------------\n",
      "Processing images_sample/SI202504021111.jpg\n",
      "Run 1/1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-15 14:45:06,555 [INFO] HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Formula 1 cars\", \"Red Bull Racing\", \"Honda engine\", \"street circuit\", \"Tokyo International Cruise Terminal Station\", \"urban racing environment\", \"race spectators\", \"fencing\", \"Japanese road signs\", \"motor racing\", \"car racing\", \"race track barriers\", \"cityscape\", \"race event\"]\n",
      "Run 1: Found 14 tags\n",
      "After deduplication: 14 unique tags\n",
      "Final tags for SI202504021111.jpg: Formula 1 cars, Red Bull Racing, Honda engine, street circuit, Tokyo International Cruise Terminal Station, urban racing environment, race spectators, fencing, Japanese road signs, motor racing, car racing, race track barriers, cityscape, race event\n",
      "--------------------------------------------------\n",
      "Successfully processed 5 images\n"
     ]
    }
   ],
   "source": [
    "# Process each image with GPT Vision API (multiple runs)\n",
    "tag_results = []\n",
    "\n",
    "for image_path in image_files:\n",
    "    print(f\"Processing {image_path}\")\n",
    "    file_name = os.path.basename(image_path)\n",
    "    \n",
    "    # Store all tag results from multiple runs\n",
    "    all_runs_tags = []\n",
    "    \n",
    "    # First run\n",
    "    print(f\"Run 1/{rerunCount+1}...\")\n",
    "    tags = gpt_client.generate_tags(image_path, taggingPrompt, print_output=True)\n",
    "    \n",
    "    # Check if we got an API key error message\n",
    "    if isinstance(tags, str) and \"Incorrect API key provided\" in tags:\n",
    "        print(\"API Key error detected. Stopping execution.\")\n",
    "        break\n",
    "    \n",
    "    if not tags:\n",
    "        print(f\"Failed to get GPT response for {file_name}\")\n",
    "        continue\n",
    "    \n",
    "    all_runs_tags.append(tags)\n",
    "    print(f\"Run 1: Found {len(tags)} tags\")\n",
    "    \n",
    "    # Additional runs if rerunCount > 0\n",
    "    if rerunCount > 0:\n",
    "        for run in range(rerunCount):\n",
    "            print(f\"Run {run+2}/{rerunCount+1}...\")\n",
    "            run_tags = gpt_client.generate_tags(image_path, taggingPrompt)\n",
    "            \n",
    "            if run_tags:\n",
    "                all_runs_tags.append(run_tags)\n",
    "                print(f\"Run {run+2}: Found {len(run_tags)} tags\")\n",
    "            else:\n",
    "                print(f\"Run {run+2}: Failed to get tags\")\n",
    "            \n",
    "            # Add a delay to prevent API rate limiting\n",
    "            time.sleep(apiDelaySeconds)\n",
    "    \n",
    "    # Deduplicate tags from all runs\n",
    "    unique_tags = image_processor.deduplicate_tags(all_runs_tags)\n",
    "    print(f\"After deduplication: {len(unique_tags)} unique tags\")\n",
    "    \n",
    "    # If we have multiple runs, consolidate results with a final verification pass\n",
    "    final_tags = tags  # Default to first run results\n",
    "    if len(all_runs_tags) > 1:\n",
    "        print(\"Performing final consolidation run...\")\n",
    "        consolidated_tags = gpt_client.consolidate_tags(image_path, unique_tags, consolidationPrompt)\n",
    "        \n",
    "        if consolidated_tags:\n",
    "            final_tags = consolidated_tags\n",
    "            print(f\"Consolidated to {len(final_tags)} verified tags\")\n",
    "        else:\n",
    "            print(\"Consolidation failed, using deduplicated tags from all runs\")\n",
    "    \n",
    "    # Store final results\n",
    "    tag_results.append({\n",
    "        \"fileName\": file_name,\n",
    "        \"tags\": final_tags\n",
    "    })\n",
    "    \n",
    "    print(f\"Final tags for {file_name}: {', '.join(final_tags)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Add a delay to prevent API rate limiting\n",
    "    time.sleep(apiDelaySeconds)\n",
    "\n",
    "print(f\"Successfully processed {len(tag_results)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa03187",
   "metadata": {},
   "source": [
    "### Write the tags to the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648ef08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 5 new entries\n",
      "Tags written to tags.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize CSV handler\n",
    "csv_handler = CsvHandler(\n",
    "    outputFilePath,\n",
    "    [\"fileName\", \"tags\"]\n",
    ")\n",
    "\n",
    "# Prepare final data for CSV\n",
    "csv_entries = []\n",
    "for result in tag_results:\n",
    "    # Skip entries where no tags were extracted\n",
    "    if not result['tags']:\n",
    "        print(f\"Skipping {result['fileName']} - no tags extracted\")\n",
    "        continue\n",
    "        \n",
    "    # Convert tags list to string for storage in CSV\n",
    "    entry = {\n",
    "        \"fileName\": result['fileName'],\n",
    "        \"tags\": \", \".join(result['tags'])\n",
    "    }\n",
    "    \n",
    "    csv_entries.append(entry)\n",
    "\n",
    "# Write to CSV\n",
    "if csv_entries:\n",
    "    csv_handler.write_tags(csv_entries)\n",
    "    print(f\"Tags written to {outputFilePath}\")\n",
    "else:\n",
    "    print(\"No tags to write to CSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5859bb",
   "metadata": {},
   "source": [
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d264fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Image 1: SI202503310625.jpg -----\n",
      "Number of tags: 22\n",
      "Tags: Formula 1 car, Red Bull Racing, car nose, front wing, suspension arms, sponsor logos, Hard Rock, TAG Heuer, Visa, Gate.io, AT&T, Ava Trade, Maui Jim, CDW, neat, Pirelli, Mobil 1, Oracle, number 1, racing livery, motorsport, racing car detail\n",
      "--------------------------------------------------\n",
      "\n",
      "----- Image 2: SI202407060351.jpg -----\n",
      "Number of tags: 14\n",
      "Tags: vintage warplanes, aerial formation flying, smoke trails, mountain landscape, green fields, rural area, aerial photography, propeller aircraft, airshow, WWII fighter planes, blue sky, scenic valley, highway, industrial area\n",
      "--------------------------------------------------\n",
      "\n",
      "----- Image 3: SI202503041658.jpg -----\n",
      "Number of tags: 22\n",
      "Tags: skiers, Henrik Kristoffersen, Lucas Pinheiro Braathen, Alexis Pinturault, ski poles, ski boots, ski race bibs, ski competition, ski World Cup, snow, celebration, winter sports, ski race podium, Red Bull logo, Audi logo, Longines logo, Vedestein logo, I Feel Slovenia banner, Kranjska Gora, ski suits, ski helmets, ski goggles\n",
      "--------------------------------------------------\n",
      "\n",
      "----- Image 4: SI202504020575.jpg -----\n",
      "Number of tags: 17\n",
      "Tags: Formula 1 drivers, racing suits, Red Bull Racing, AlphaTauri, Oracle Red Bull Racing cap, smiling, sitting, race track environment, sponsor logos, Visa, AT&T, Honda, Rauch, ROKiT, HRC, Red Bull logos, team members\n",
      "--------------------------------------------------\n",
      "\n",
      "----- Image 5: SI202504021111.jpg -----\n",
      "Number of tags: 14\n",
      "Tags: Formula 1 cars, Red Bull Racing, Honda engine, street circuit, Tokyo International Cruise Terminal Station, urban racing environment, race spectators, fencing, Japanese road signs, motor racing, car racing, race track barriers, cityscape, race event\n",
      "--------------------------------------------------\n",
      "\n",
      "Total images processed: 5\n",
      "\n",
      "Output CSV contains 5 entries:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SI202503310625.jpg</td>\n",
       "      <td>Formula 1 car, Red Bull Racing, car nose, fron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SI202407060351.jpg</td>\n",
       "      <td>vintage warplanes, aerial formation flying, sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SI202503041658.jpg</td>\n",
       "      <td>skiers, Henrik Kristoffersen, Lucas Pinheiro B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SI202504020575.jpg</td>\n",
       "      <td>Formula 1 drivers, racing suits, Red Bull Raci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SI202504021111.jpg</td>\n",
       "      <td>Formula 1 cars, Red Bull Racing, Honda engine,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             fileName                                               tags\n",
       "0  SI202503310625.jpg  Formula 1 car, Red Bull Racing, car nose, fron...\n",
       "1  SI202407060351.jpg  vintage warplanes, aerial formation flying, sm...\n",
       "2  SI202503041658.jpg  skiers, Henrik Kristoffersen, Lucas Pinheiro B...\n",
       "3  SI202504020575.jpg  Formula 1 drivers, racing suits, Red Bull Raci...\n",
       "4  SI202504021111.jpg  Formula 1 cars, Red Bull Racing, Honda engine,..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display summary of processed images\n",
    "for i, result in enumerate(tag_results):\n",
    "    print(f\"\\n----- Image {i+1}: {result['fileName']} -----\")\n",
    "    print(f\"Number of tags: {len(result['tags'])}\")\n",
    "    print(f\"Tags: {', '.join(result['tags'])}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"\\nTotal images processed: {len(tag_results)}\")\n",
    "\n",
    "# Try to read the output CSV file if it exists\n",
    "try:\n",
    "    if os.path.exists(outputFilePath):\n",
    "        df = pd.read_csv(outputFilePath)\n",
    "        print(f\"\\nOutput CSV contains {len(df)} entries:\")\n",
    "        display(df)\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't read output CSV: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
